"""
MCPæ™ºèƒ½ä½“å°è£… - ä¸ºWebåç«¯ä½¿ç”¨
åŸºäº test.py ä¸­çš„ SimpleMCPAgentï¼Œä¼˜åŒ–ä¸ºé€‚åˆWebSocketæµå¼æ¨é€çš„ç‰ˆæœ¬
"""

import os
import json
import asyncio
from typing import Dict, List, Any, AsyncGenerator
from pathlib import Path
from datetime import datetime, timedelta

from dotenv import load_dotenv, find_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langchain_mcp_adapters.client import MultiServerMCPClient

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. MCPé…ç½®ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MCPConfig:
    """MCPé…ç½®ç®¡ç†"""

    def __init__(self, config_file):
        self.config_file = config_file
        self.default_config = {}

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if Path(self.config_file).exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")

        # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        self.save_config(self.default_config)
        return self.default_config

    def save_config(self, config: Dict[str, Any]):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Webç‰ˆMCPæ™ºèƒ½ä½“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class WebMCPAgent:
    """Webç‰ˆMCPæ™ºèƒ½ä½“ - æ”¯æŒæµå¼æ¨é€"""

    def __init__(self):
        # ä¿®å¤ï¼šä½¿ç”¨configç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶
        config_path = Path(__file__).parent / "config/mcp_service.json"
        self.config = MCPConfig(str(config_path))
        self.llm = None
        self.mcp_client = None
        self.tools = []
        # æ–°å¢ï¼šæŒ‰æœåŠ¡å™¨åˆ†ç»„çš„å·¥å…·å­˜å‚¨
        self.tools_by_server = {}
        self.server_configs = {}

        # åŠ è½½ .env å¹¶è®¾ç½®APIç¯å¢ƒå˜é‡ï¼ˆä¸è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼‰
        try:
            load_dotenv(find_dotenv(), override=True)
        except Exception:
            # å¿½ç•¥ .env åŠ è½½é”™è¯¯ï¼Œç»§ç»­ä»ç³»ç»Ÿç¯å¢ƒè¯»å–
            pass

        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.api_key = os.getenv("OPENAI_API_KEY", "").strip()
        self.base_url = os.getenv("OPENAI_BASE_URL", "").strip()
        self.model_name = os.getenv("OPENAI_MODEL", os.getenv("OPENAI_MODEL_NAME", "deepseek-chat")).strip()

        # æ•°å€¼é…ç½®ï¼Œå¸¦é»˜è®¤
        try:
            self.temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.2"))
        except Exception:
            self.temperature = 0.2
        try:
            self.timeout = int(os.getenv("OPENAI_TIMEOUT", "60"))
        except Exception:
            self.timeout = 60

        # å°†å…³é”®é…ç½®åŒæ­¥åˆ°ç¯å¢ƒï¼ˆä¾›åº•å±‚SDKä½¿ç”¨ï¼‰ï¼Œä¸è¦†ç›–å¤–éƒ¨å·²è®¾å€¼
        if self.api_key and not os.getenv("OPENAI_API_KEY"):
            os.environ["OPENAI_API_KEY"] = self.api_key
        if self.base_url and not os.getenv("OPENAI_BASE_URL"):
            os.environ["OPENAI_BASE_URL"] = self.base_url

    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        try:
            # åˆå§‹åŒ–å¤§æ¨¡å‹
            if not os.getenv("OPENAI_API_KEY"):
                raise RuntimeError("ç¼ºå°‘ OPENAI_API_KEYï¼Œè¯·åœ¨ .env æˆ–ç³»ç»Ÿç¯å¢ƒä¸­é…ç½®")

            # ChatOpenAI æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å– base_url
            self.llm = ChatOpenAI(
                model=self.model_name,
                temperature=self.temperature,
                timeout=self.timeout,
                max_retries=3,
            )

            # åŠ è½½MCPé…ç½®å¹¶è¿æ¥
            mcp_config = self.config.load_config()
            self.server_configs = mcp_config.get("servers", {})

            if not self.server_configs:
                print("âŒ æ²¡æœ‰é…ç½®MCPæœåŠ¡å™¨")
                return False

            print("ğŸ”— æ­£åœ¨è¿æ¥MCPæœåŠ¡å™¨...")
            
            # å…ˆæµ‹è¯•æœåŠ¡å™¨è¿æ¥
            import aiohttp
            import asyncio
            
            for server_name, server_config in self.server_configs.items():
                try:
                    url = server_config.get('url')
                    if not url:
                        print(f"âš ï¸ æœåŠ¡å™¨ {server_name} ç¼ºå°‘ url é…ç½®ï¼Œè·³è¿‡è¿æ¥æµ‹è¯•")
                        continue
                    print(f"ğŸ§ª æµ‹è¯•è¿æ¥åˆ° {server_name}: {url}")
                    async with aiohttp.ClientSession() as session:
                        async with session.post(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                            print(f"âœ… {server_name} è¿æ¥æµ‹è¯•æˆåŠŸ (çŠ¶æ€: {response.status})")
                except Exception as test_e:
                    print(f"âš ï¸ {server_name} è¿æ¥æµ‹è¯•å¤±è´¥: {test_e}")
            
            # åˆ›å»ºMCPå®¢æˆ·ç«¯ - å¼ºåˆ¶æ¸…é™¤ç¼“å­˜å¹¶ç¦ç”¨HTTP/2
            import httpx

            def http_client_factory(headers=None, timeout=None, auth=None):
                return httpx.AsyncClient(
                    http2=False,  # ç¦ç”¨HTTP/2
                    headers=headers,
                    timeout=timeout,
                    auth=auth
                )

            # æ›´æ–°æœåŠ¡å™¨é…ç½®ä»¥ä½¿ç”¨è‡ªå®šä¹‰çš„httpxå®¢æˆ·ç«¯å·¥å‚
            for server_name in self.server_configs:
                # é¿å…æ±¡æŸ“åŸé…ç½®å¯¹è±¡ï¼Œå¤åˆ¶åæ·»åŠ å·¥å‚
                server_cfg = dict(self.server_configs[server_name])
                server_cfg['httpx_client_factory'] = http_client_factory
                self.server_configs[server_name] = server_cfg

            self.mcp_client = MultiServerMCPClient(self.server_configs)

            # æ”¹ä¸ºä¸²è¡Œè·å–å·¥å…·ï¼Œé¿å…å¹¶å‘é—®é¢˜
            print("ğŸ”§ æ­£åœ¨é€ä¸ªè·å–æœåŠ¡å™¨å·¥å…·...")
            for server_name in self.server_configs.keys():
                try:
                    print(f"â”€â”€â”€ æ­£åœ¨ä»æœåŠ¡å™¨ '{server_name}' è·å–å·¥å…· â”€â”€â”€")
                    server_tools = await self.mcp_client.get_tools(server_name=server_name)
                    self.tools.extend(server_tools)
                    self.tools_by_server[server_name] = server_tools
                    print(f"âœ… ä» {server_name} è·å–åˆ° {len(server_tools)} ä¸ªå·¥å…·")
                except Exception as e:
                    print(f"âŒ ä»æœåŠ¡å™¨ '{server_name}' è·å–å·¥å…·å¤±è´¥: {e}")
                    self.tools_by_server[server_name] = []
            
            # éªŒè¯å·¥å…·æ¥æºï¼Œç¡®ä¿åªæœ‰é…ç½®æ–‡ä»¶ä¸­çš„æœåŠ¡å™¨
            print(f"ğŸ” é…ç½®çš„æœåŠ¡å™¨: {list(self.server_configs.keys())}")
            print(f"ğŸ” å®é™…è·å–åˆ°çš„å·¥å…·æ•°é‡: {len(self.tools)}")
            
            # åˆ†ç»„é€»è¾‘å·²åœ¨ä¸Šé¢çš„å¾ªç¯ä¸­å®Œæˆï¼Œæ— éœ€é¢å¤–è°ƒç”¨

            print(f"âœ… æˆåŠŸè¿æ¥ï¼Œè·å–åˆ° {len(self.tools)} ä¸ªå·¥å…·")
            print(f"ğŸ“Š æœåŠ¡å™¨åˆ†ç»„æƒ…å†µ: {dict((name, len(tools)) for name, tools in self.tools_by_server.items())}")

            # ç»‘å®šå·¥å…·åˆ°å¤§æ¨¡å‹
            self.llm = self.llm.bind_tools(self.tools)
            # todo è¿˜å¯ä»¥è€ƒè™‘promptå’Œresourcesè¿›è¡Œå¤§æ¨¡å‹çš„ç»‘å®š

            print("ğŸ¤– Web MCPæ™ºèƒ½åŠ©æ‰‹å·²å¯åŠ¨ï¼")
            return True

        except Exception as e:
            import traceback
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            
            # å°è¯•æ¸…ç†å¯èƒ½çš„è¿æ¥
            if hasattr(self, 'mcp_client') and self.mcp_client:
                try:
                    await self.mcp_client.close()
                except:
                    pass
            return False

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        now = datetime.now()
        current_date = now.strftime("%Yå¹´%mæœˆ%dæ—¥")
        current_weekday = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]

        return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨MCPå·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆå„ç§ä»»åŠ¡ã€‚

å½“å‰æ—¶é—´ä¿¡æ¯ï¼š
ğŸ“… ä»Šå¤©æ˜¯ï¼š{current_date} ({current_weekday})

å·¥ä½œåŸåˆ™ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡
3. æ¸…æ¥šåœ°è§£é‡Šæ“ä½œè¿‡ç¨‹å’Œç»“æœ
4. å¦‚æœé‡åˆ°é—®é¢˜ï¼Œæä¾›å…·ä½“çš„è§£å†³å»ºè®®

è¯·å§‹ç»ˆä»¥ç”¨æˆ·éœ€æ±‚ä¸ºä¸­å¿ƒï¼Œé«˜æ•ˆåœ°ä½¿ç”¨å¯ç”¨å·¥å…·ã€‚"""

    async def chat_stream(self, user_input: str, history: List[Dict[str, Any]] = None) -> AsyncGenerator[Dict[str, Any], None]:
        """æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥ - ä¸ºWebSocketæ¨é€ä¼˜åŒ–"""
        try:
            print(f"ğŸ¤– å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input[:50]}...")
            yield {"type": "status", "content": "å¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚..."}

            # æ„å»ºæ¶ˆæ¯å†å²
            messages = [
                {"role": "system", "content": self._get_system_prompt()}
            ]

            # æ·»åŠ å†å²è®°å½•
            if history:
                for record in history:
                    messages.append({"role": "user", "content": record['user_input']})
                    if record.get('ai_response'):
                        messages.append({"role": "assistant", "content": record['ai_response']})

            messages.append({"role": "user", "content": user_input})

            max_iterations = 10
            iteration = 0

            while iteration < max_iterations:
                iteration += 1

                yield {"type": "status", "content": f"ç¬¬ {iteration} è½®æ¨ç†..."}

                # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ¨ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                try:
                    print(f"ğŸ§  ç¬¬ {iteration} è½®æ¨ç†å¼€å§‹...")
                    # ainvoke ä¸€æ¬¡æ€§è¿”å›ç»“æœ
                    response = await self.llm.ainvoke(messages)
                    print(f"âœ… ç¬¬ {iteration} è½®æ¨ç†å®Œæˆ")
                except Exception as e:
                    print(f"âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
                    yield {
                        "type": "error",
                        "content": f"å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}"
                    }
                    return

                # æµå¼æ˜¾ç¤ºAIæ€è€ƒå†…å®¹ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
                if response.content:
                    # å¼€å§‹AIæ€è€ƒ
                    yield {
                        "type": "ai_thinking_start",
                        "iteration": iteration
                    }

                    # é‡æ–°æµå¼ç”Ÿæˆæ€è€ƒå†…å®¹ï¼ˆçœŸæµå¼ï¼‰
                    thinking_content = ""
                    # astream æµå¼è¿”å›ç»“æœ
                    async for chunk in self.llm.astream(messages):
                        if hasattr(chunk, 'content') and chunk.content:
                            content = chunk.content
                            thinking_content += content
                            yield {
                                "type": "ai_thinking_chunk",
                                "content": content,
                                "iteration": iteration
                            }

                    # ç»“æŸAIæ€è€ƒ
                    yield {
                        "type": "ai_thinking_end",
                        "content": thinking_content,
                        "iteration": iteration
                    }

                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                if hasattr(response, 'tool_calls') and response.tool_calls:
                    print(f"ğŸ”§ æ£€æµ‹åˆ° {len(response.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                    yield {
                        "type": "tool_plan",
                        "content": f"AIå†³å®šè°ƒç”¨ {len(response.tool_calls)} ä¸ªå·¥å…·",
                        "tool_count": len(response.tool_calls)
                    }

                    # ä¸²è¡Œæ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                    for i, tool_call in enumerate(response.tool_calls, 1):
                        tool_name = tool_call['name']
                        tool_args = tool_call.get('args', {})
                        # é¢å¤–æ·»åŠ ç”¨æˆ·è¾“å…¥å±æ€§ ä¸»è¦é’ˆå¯¹creat_workflowå·¥å…·ä½¿ç”¨ é€šè¿‡è¾“å…¥ç”¨æˆ·éœ€æ±‚ç»“åˆLLMåˆå§‹ç”Ÿæˆç»“æœè¿›è¡Œè¿­ä»£ç²¾åº¦æå‡
                        tool_args["userInput"] = user_input
                        tool_id = tool_call.get('id', f"call_{i}")

                        print(f"ğŸ”§ æ‰§è¡Œå·¥å…· {i}/{len(response.tool_calls)}: {tool_name}")

                        # æ¨é€å·¥å…·å¼€å§‹æ‰§è¡Œ
                        yield {
                            "type": "tool_start",
                            "tool_id": tool_id,
                            "tool_name": tool_name,
                            "tool_args": tool_args,
                            "progress": f"{i}/{len(response.tool_calls)}"
                        }

                        try:
                            # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                            target_tool = None
                            for tool in self.tools:
                                if tool.name == tool_name:
                                    target_tool = tool
                                    break

                            if target_tool is None:
                                error_msg = f"å·¥å…· '{tool_name}' æœªæ‰¾åˆ°"
                                print(f"âŒ {error_msg}")
                                yield {
                                    "type": "tool_error",
                                    "tool_id": tool_id,
                                    "error": error_msg
                                }
                                tool_result = f"é”™è¯¯: {error_msg}"
                            else:
                                # æ‰§è¡Œå·¥å…·
                                print(f"ğŸ”§ æ­£åœ¨æ‰§è¡Œå·¥å…·: {tool_name}")

                                tool_result = await target_tool.ainvoke(tool_args)
                                print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_name}")

                                # æ¨é€å·¥å…·æ‰§è¡Œç»“æœ
                                yield {
                                    "type": "tool_end",
                                    "tool_id": tool_id,
                                    "tool_name": tool_name,
                                    "result": str(tool_result)
                                }

                        except Exception as e:
                            error_msg = f"å·¥å…·æ‰§è¡Œå‡ºé”™: {e}"
                            print(f"âŒ {error_msg}")
                            yield {
                                "type": "tool_error",
                                "tool_id": tool_id,
                                "error": error_msg
                            }
                            tool_result = f"é”™è¯¯: {error_msg}"

                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append({
                            "role": "assistant",
                            "content": response.content or "",
                            "tool_calls": [tool_call]
                        })
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_id,
                            "name": tool_name,
                            "content": str(tool_result)
                        })

                    # ç»§ç»­ä¸‹ä¸€è½®æ¨ç†
                    continue

                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ - è¿™æ˜¯æœ€ç»ˆå›å¤ï¼Œä¸æ˜¾ç¤ºåœ¨æ€ç»´æµä¸­
                    # ç¡®ä¿ thinking_content å·²å®šä¹‰
                    try:
                        tc_len = len(thinking_content)  # å¯èƒ½æœªå®šä¹‰
                    except Exception:
                        tc_len = 0
                    print(f"ğŸ’¬ å½“å‰å†…å®¹ä¸ºæœ€ç»ˆå›å¤ï¼Œé•¿åº¦: {tc_len}")

                    # å‘é€æœ€ç»ˆå›å¤å¼€å§‹ä¿¡å·
                    yield {
                        "type": "ai_response_start",  
                        "content": "AIæ­£åœ¨å›å¤..."
                    }

                    # é‡æ–°æµå¼ç”Ÿæˆå›å¤ï¼ˆå› ä¸ºä¸Šé¢å·²ç»ç”¨ainvokeè·å–äº†æ€è€ƒå†…å®¹ï¼‰todo è¿™ä¸€å¤šä½™çš„astreamæ˜¯å¦å¯ä»¥é€šè¿‡å‰å‡ æ¬¡çš„ç»“æœå¾—åˆ° è€Œé¿å…å¤šä½™çš„è¯·æ±‚llm
                    final_response = ""
                    async for chunk in self.llm.astream(messages):
                        if hasattr(chunk, 'content') and chunk.content:
                            content = chunk.content
                            final_response += content
                            yield {
                                "type": "ai_response_chunk",
                                "content": content
                            }

                    yield {
                        "type": "ai_response_end",
                        "content": final_response
                    }

                    return

            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            error_msg = f"è¾¾åˆ°æœ€å¤§æ¨ç†è½®æ•° ({max_iterations})ï¼Œåœæ­¢æ‰§è¡Œ"
            print(f"âš ï¸ {error_msg}")
            yield {
                "type": "error",
                "content": error_msg
            }

        except Exception as e:
            import traceback
            print(f"âŒ chat_stream å¼‚å¸¸: {e}")
            print("ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            yield {
                "type": "error",
                "content": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            }

    def get_tools_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰MCPæœåŠ¡å™¨åˆ†ç»„"""
        if not self.tools_by_server:
            return {"servers": {}, "total_tools": 0, "server_count": 0}
        
        servers_info = {}
        total_tools = 0
        
        # æŒ‰æœåŠ¡å™¨åˆ†ç»„æ„å»ºå·¥å…·ä¿¡æ¯
        for server_name, server_tools in self.tools_by_server.items():
            tools_info = []
            
            for tool in server_tools:
                tool_info = {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": {},
                    "required": []
                }
                
                # è·å–å‚æ•°ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬
                try:
                    schema = None
                    
                    # æ–¹æ³•1: å°è¯•ä½¿ç”¨args_schema (LangChainå·¥å…·å¸¸ç”¨)
                    if hasattr(tool, 'args_schema') and tool.args_schema:
                        if isinstance(tool.args_schema, dict):
                            schema = tool.args_schema
                        elif hasattr(tool.args_schema, 'model_json_schema'):
                            schema = tool.args_schema.model_json_schema()
                    
                    # æ–¹æ³•2: å¦‚æœæ²¡æœ‰args_schemaï¼Œå°è¯•tool_call_schema
                    if not schema and hasattr(tool, 'tool_call_schema') and tool.tool_call_schema:
                        schema = tool.tool_call_schema
                    
                    # æ–¹æ³•3: æœ€åå°è¯•input_schema
                    if not schema and hasattr(tool, 'input_schema') and tool.input_schema:
                        if isinstance(tool.input_schema, dict):
                            schema = tool.input_schema
                        elif hasattr(tool.input_schema, 'model_json_schema'):
                            try:
                                schema = tool.input_schema.model_json_schema()
                            except:
                                pass
                    
                    # è§£æschema
                    if schema and isinstance(schema, dict):
                        if 'properties' in schema:
                            tool_info["parameters"] = schema['properties']
                            tool_info["required"] = schema.get('required', [])
                        elif 'type' in schema and schema.get('type') == 'object' and 'properties' in schema:
                            tool_info["parameters"] = schema['properties']
                            tool_info["required"] = schema.get('required', [])
                
                except Exception as e:
                    # å¦‚æœå‡ºé”™ï¼Œè‡³å°‘ä¿ç•™å·¥å…·çš„åŸºæœ¬ä¿¡æ¯
                    print(f"âš ï¸ è·å–å·¥å…· '{tool.name}' å‚æ•°ä¿¡æ¯å¤±è´¥: {e}")
                
                tools_info.append(tool_info)
            
            # æ·»åŠ æœåŠ¡å™¨ä¿¡æ¯
            servers_info[server_name] = {
                "name": server_name,
                "tools": tools_info,
                "tool_count": len(tools_info)
            }
            
            total_tools += len(tools_info)
        
        return {
            "servers": servers_info,
            "total_tools": total_tools,
            "server_count": len(servers_info)
        }

    async def close(self):
        """å…³é—­è¿æ¥"""
        try:
            if self.mcp_client and hasattr(self.mcp_client, 'close'):
                await self.mcp_client.close()
        except:
            pass
